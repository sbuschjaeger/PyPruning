<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Extending PyPruning &mdash; PyPruning  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Reproducing results from literature" href="papers.html" />
    <link rel="prev" title="Random" href="random.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> PyPruning
            <img src="_static/pruning-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">PyPruning</a></li>
<li class="toctree-l1"><a class="reference internal" href="available.html">Pruning an ensemble</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Extending PyPruning</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Extending PyPruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#implementing-a-custom-metric">Implementing a custom metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="#implementing-a-custom-pruner">Implementing a custom pruner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-PyPruning.PruningClassifier">PyPruning.PruningClassifier module</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="papers.html">Reproducing results from literature</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyPruning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Extending PyPruning</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/sbuschjaeger/pypruning/blob/master/docs/extending.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="extending-pypruning">
<h1>Extending PyPruning<a class="headerlink" href="#extending-pypruning" title="Permalink to this headline"></a></h1>
<div class="toctree-wrapper compound">
</div>
<p>If you want to implement your own pruning method then there are two ways:</p>
<section id="implementing-a-custom-metric">
<h2>Implementing a custom metric<a class="headerlink" href="#implementing-a-custom-metric" title="Permalink to this headline"></a></h2>
<p>You can implement your own metric for <a class="reference internal" href="greedy.html#module-PyPruning.GreedyPruningClassifier" title="PyPruning.GreedyPruningClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">GreedyPruningClassifier</span></code></a>, <a class="reference internal" href="MIQP.html#module-PyPruning.MIQPPruningClassifier" title="PyPruning.MIQPPruningClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">MIQPPruningClassifier</span></code></a> or a <a class="reference internal" href="rank.html#module-PyPruning.RankPruningClassifier" title="PyPruning.RankPruningClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">RankPruningClassifier</span></code></a> you simply have to implement a python function that should be <strong>minimized</strong>. The specific interface required by each method slightly differs so please check out the specific documentation for the method of your choice. In all cases, each method expects functions with at-least three parameters</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">i</span></code> (int): The classifier which should be rated</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ensemble_proba</span></code> (A (M, N, C) matrix ): All N predictions of all M classifier in the entire ensemble for all C classes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">target</span></code> (list / array): A list / array of class targets.</p></li>
</ul>
<p>Note that <code class="docutils literal notranslate"><span class="pre">ensemble_proba</span></code> contains all class probabilities predicted by all members in the ensemble. So in order to get individual class predictions for the i-th classifier you can access it via <code class="docutils literal notranslate"><span class="pre">ensemble_proba[i,:,:]</span></code>. A complete example which simply computes the error of each method would be</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">individual_error</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">ensemble_proba</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
   <span class="n">iproba</span> <span class="o">=</span> <span class="n">ensemble_proba</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:]</span>
   <span class="k">return</span> <span class="p">(</span><span class="n">iproba</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">!=</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="implementing-a-custom-pruner">
<h2>Implementing a custom pruner<a class="headerlink" href="#implementing-a-custom-pruner" title="Permalink to this headline"></a></h2>
<p>You can implement your own pruner as a well. In this case you just have to implement the <a class="reference internal" href="#module-PyPruning.PruningClassifier" title="PyPruning.PruningClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">PruningClassifier</span></code></a> class. To do so, you just need to implement the <code class="docutils literal notranslate"><span class="pre">prune_(self,</span> <span class="pre">proba,</span> <span class="pre">target)</span></code> function which receives a list of all predictions of all classifiers as well as the corresponding data and targets. The function is supposed to return a list of indices corresponding to the chosen estimators as well as the corresponding weights. If you need access to the estimators as well (and not just their predictions) you can access <code class="docutils literal notranslate"><span class="pre">self.estimators_</span></code> which already contains a copy of each classier. For more details have a look at the <code class="xref py py-class docutils literal notranslate"><span class="pre">PruningClassifier.py</span></code> interface. An example implementation could be:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RandomPruningClassifier</span><span class="p">(</span><span class="n">PruningClassifier</span><span class="p">):</span>

   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

   <span class="k">def</span> <span class="nf">prune_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">proba</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
      <span class="n">n_received</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">proba</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">&gt;=</span> <span class="n">n_received</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_received</span><span class="p">),</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">n_received</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_received</span><span class="p">)]</span>
      <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_received</span><span class="p">),</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">),</span> <span class="p">[</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)]</span>
</pre></div>
</div>
<section id="module-PyPruning.PruningClassifier">
<span id="pypruning-pruningclassifier-module"></span><h3>PyPruning.PruningClassifier module<a class="headerlink" href="#module-PyPruning.PruningClassifier" title="Permalink to this headline"></a></h3>
<dl class="py class">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">PyPruning.PruningClassifier.</span></span><span class="sig-name descname"><span class="pre">PruningClassifier</span></span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>This abstract class forms the basis of all pruning methods and offers a unified interface. New pruning methods must extend this class and implement the <a href="#id1"><span class="problematic" id="id2">prune_</span></a> method as detailed below.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.weights_">
<span class="sig-name descname"><span class="pre">weights_</span></span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.weights_" title="Permalink to this definition"></a></dt>
<dd><p>An array of weights corresponding to each classifier in <a href="#id3"><span class="problematic" id="id4">self.estimators_</span></a></p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>numpy array</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.estimators_">
<span class="sig-name descname"><span class="pre">estimators_</span></span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.estimators_" title="Permalink to this definition"></a></dt>
<dd><p>A list of estimators</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.n_classes_">
<span class="sig-name descname"><span class="pre">n_classes_</span></span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.n_classes_" title="Permalink to this definition"></a></dt>
<dd><p>The number of classes the pruned ensemble supports.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.predict" title="Permalink to this definition"></a></dt>
<dd><p>Predict classes using the pruned model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The samples to be predicted.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The predicted classes.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array, shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.predict_proba" title="Permalink to this definition"></a></dt>
<dd><p>Predict class probabilities using the pruned model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> (<em>array-like</em><em> or </em><em>sparse matrix</em><em>, </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The samples to be predicted.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>y</strong> – The predicted class probabilities.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>array, shape (n_samples,C)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.prune">
<span class="sig-name descname"><span class="pre">prune</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">estimators</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.prune" title="Permalink to this definition"></a></dt>
<dd><p>Prunes the given ensemble on the supplied dataset. There are a few assumptions placed on the behavior of the individual classifiers in <cite>estimators</cite>. If you use scikit-learn classifier and any classifier implementing their interface they should work without a problem. The detailed assumptions are listed below:</p>
<ul class="simple">
<li><p><cite>predict_proba</cite>: Each estimator should offer a predict_proba function which returns the class probabilities for each class on a batch of data</p></li>
<li><p><cite>n_classes_</cite>: Each estimator should offer a field on the number of classes it has been trained on. Ideally, this should be the same for all classifier in the ensemble but might differ e.g. due to different bootstrap samples. This field is not accessed if you manually supply <cite>n_classes</cite> as parameter to this function</p></li>
<li><p><cite>classes_</cite>: Each estimator should offer a class mapping which shows the order of classes returned by predict_proba. Usually this should simply be [0,1,2,3,4] for 5 classes, but if your classifier returns class probabilities in a different order, e.g. [2,1,0,3,4] you should store this order in <cite>classes_</cite>. This field is not accessed if you manually supply <cite>classes</cite> as parameter to this function</p></li>
</ul>
<p>For pruning this function calls <cite>predict_proba</cite> on each classifier in <cite>estimators</cite> and then calls <cite>prune_</cite> of the implementing class. After pruning, it extracts the selected classifiers from <cite>estimators</cite> with their corresponding weight and stores them in <cite>self.weights_</cite> and <cite>self.estimators_</cite></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>numpy matrix</em>) – A (N, d) matrix with the datapoints used for pruning where N is the number of data points and d is the dimensionality</p></li>
<li><p><strong>Y</strong> (<em>numpy array / list of ints</em>) – A numpy array or list of N integers where each integer represents the class for each example. Classes should start with 0, so that for C classes the integer 0,1,…,C-1 are used</p></li>
<li><p><strong>estimators</strong> (<em>list</em>) – A list of estimators from which the pruned ensemble is selected.</p></li>
<li><p><strong>classes</strong> (<em>numpy array / list of ints</em>) – Contains the class mappings of each base learner in the order which is returned by predict_proba. Usually this should be something like [0,1,2,3,4] for a 5 class problem. However, sometimes weird stuff happens and the mapping might be [2,1,0,3,4]. In this case, you can manually supply the list of mappings</p></li>
<li><p><strong>n_classes</strong> (<em>int</em>) – The total number of classes. Usually, this it should be n_classes = len(classes). However, sometimes estimators are only fitted on a subset of data (e.g. during cross validation or bootstrapping) and the prune set might contain classes which are not in the original training set and vice-versa. In this case its best to supply n_classes beforehand.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>The pruned ensemble (self).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="PyPruning.PruningClassifier.PruningClassifier.prune_">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">prune_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">proba</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#PyPruning.PruningClassifier.PruningClassifier.prune_" title="Permalink to this definition"></a></dt>
<dd><p>Prunes the ensemble using the ensemble predictions proba and the pruning data targets / data. If the pruning method requires access to the original ensemble members you can access these via <a href="#id5"><span class="problematic" id="id6">self.estimators_</span></a>. Note that <a href="#id7"><span class="problematic" id="id8">self.estimators_</span></a> is already a deep-copy of the estimators so you are also free to change the estimators in this list if you want to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>proba</strong> (<em>numpy matrix</em>) – A (N,M,C) matrix which contains the individual predictions of each ensemble member on the pruning data. Each ensemble prediction is generated via predict_proba. N is size of the pruning data, M the size of the base ensemble and C is the number of classes</p></li>
<li><p><strong>target</strong> (<em>numpy array of ints</em>) – A numpy array or list of N integers where each integer represents the class for each example. Classes should start with 0, so that for C classes the integer 0,1,…,C-1 are used</p></li>
<li><p><strong>data</strong> (<em>numpy matrix</em><em>, </em><em>optional</em>) – The data points in a (N, M) matrix on which the proba has been computed, where N is the pruning set size and M is the number of classifier in the original ensemble. This can be used by a pruning method if required, but most methods do not require the actual data points but only the individual predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>A tuple of indices and weights (idx, weights) with the following properties</em></p></li>
<li><p><strong>idx</strong> (<em>numpy array / list of ints</em>) – A list of integers which classifier should be selected from <a href="#id9"><span class="problematic" id="id10">self.estimators_</span></a>. Any changes made to <a href="#id11"><span class="problematic" id="id12">self.estimators_</span></a> are also reflected here, so make sure that the order of classifier in proba and <a href="#id13"><span class="problematic" id="id14">self.estimators_</span></a> remains the same (or you return idx accordingly)</p></li>
<li><p><strong>weights</strong> (<em>numpy array / list of floats</em>) – The individual weights for each selected classifier. The size of this array should match the size of idx (and not the size of the original base ensemble).</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="random.html" class="btn btn-neutral float-left" title="Random" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="papers.html" class="btn btn-neutral float-right" title="Reproducing results from literature" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Sebastian Buschjäger.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>